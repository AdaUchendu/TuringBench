{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e798778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce12bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassPredictionError\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ebed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a2bf3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\adaku\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from datasets) (1.0.3)\n",
      "Requirement already satisfied: dill in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from datasets) (3.0.12)\n",
      "Requirement already satisfied: xxhash in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from datasets) (2.0.0)\n",
      "Collecting tqdm<4.50.0,>=4.27\n",
      "  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from datasets) (1.18.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adaku\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->datasets) (1.15.0)\n",
      "Installing collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.59.0\n",
      "    Uninstalling tqdm-4.59.0:\n",
      "      Successfully uninstalled tqdm-4.59.0\n",
      "Successfully installed tqdm-4.49.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyro-ppl 1.3.1 requires opt-einsum>=2.3.2, which is not installed.\n",
      "spacy 2.1.4 requires jsonschema<3.1.0,>=2.6.0, but you have jsonschema 3.2.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc02db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664e2eb3",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7794f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset('turingbench/TuringBench',name='AA', split='train')\n",
    "train = pd.DataFrame.from_dict(train)\n",
    "\n",
    "test = load_dataset('turingbench/TuringBench',name='AA', split='test')\n",
    "test = pd.DataFrame.from_dict(test)\n",
    "\n",
    "valid = load_dataset('turingbench/TuringBench',name='AA', split='valid')\n",
    "valid = pd.DataFrame.from_dict(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b630e8",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc97ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    " \n",
    "# Function to generate n-grams from sentences.\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
    "    \n",
    "    return [ ' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bbb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngrams = []\n",
    "for i in train['Generation']:\n",
    "    train_ngrams.append(extract_ngrams(str(i), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0844422",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ngrams = []\n",
    "for i in test['Generation']:\n",
    "    test_ngrams.append(extract_ngrams(str(i), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4cf0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa1d6818",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(train, test, train_label, test_label):\n",
    "            \n",
    "        \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear', gamma=\"auto\")  \n",
    "    v = TfidfVectorizer()\n",
    "\n",
    "    \n",
    "    train_corpus = train\n",
    "    train_corpus = [\" \".join(x) for x in train_corpus]\n",
    "\n",
    "    test_corpus = test\n",
    "    test_corpus = [\" \".join(x) for x in test_corpus]\n",
    "    \n",
    "    train_vector = v.fit_transform(train_corpus)\n",
    "    test_vector = v.transform(test_corpus)\n",
    "    \n",
    "    y_train = train_label\n",
    "    y_test = test_label\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "    print(classification_report(y_test, pred, labels = list(train_label.unique()),\n",
    "                                digits=4))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return y_test, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea096116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM 3-grams \n",
    "\n",
    "classify(train = train_ngrams, test = test_ngrams, \n",
    "             train_label = train['label'], test_label = test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca919161",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846fc2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(train, test):\n",
    "            \n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = list(train['Generation']), list(test['Generation']), list(train['label']), list(test['label'])\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=1234,n_estimators=150,n_jobs=-1)\n",
    "#     clf = LogisticRegression(solver = 'lbfgs',multi_class='auto')\n",
    "    \n",
    "    v = TfidfVectorizer()\n",
    "    \n",
    "    train_corpus = X_train\n",
    "#     train_corpus = [[word.lower() for word in text.split()] for text in data]\n",
    "#     train_corpus = [\" \".join(x) for x in train_corpus]\n",
    "\n",
    "    test_corpus = X_test\n",
    "#     test_corpus = [\" \".join(x) for x in test_corpus]\n",
    "\n",
    "#     ax = axes.set_ylim([0,300])\n",
    "    train_vector = v.fit_transform(train_corpus)\n",
    "    test_vector = v.transform(test_corpus)\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "    LABEL = list(train['label'].unique())\n",
    "    \n",
    "    # Instantiate the classification model and visualizer\n",
    "    visualizer = ClassPredictionError(clf, classes= LABEL)\n",
    "\n",
    "    # Fit the training data to the visualizer\n",
    "    visualizer.fit(train_vector, y_train)\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    visualizer.score(test_vector, y_test)\n",
    "\n",
    "    # Draw visualization\n",
    "    visualizer.show()\n",
    "    \n",
    "    \n",
    "    matrix = confusion_matrix(y_test, pred, labels = LABEL)\n",
    "    mat = matrix.diagonal()/matrix.sum(axis=1)\n",
    "    print(classification_report(y_test, pred, labels = LABEL, digits=4))\n",
    "    print('confusion matrix: ', mat)\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(y_test, pred, labels=LABEL)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "#     plt.xticks(rotation=70)\n",
    "\n",
    "    ax.xaxis.set_ticklabels(LABEL)\n",
    "    ax.yaxis.set_ticklabels(LABEL)\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "\n",
    "\n",
    "    Accuracy = accuracy_score(y_test,pred)\n",
    "    F1 = f1_score(y_test, pred, average='macro')\n",
    "    print(\"Accuracy:\", Accuracy)\n",
    "    \n",
    "    rec = recall_score(y_test, pred, average='macro')\n",
    "    print('Recall: ', rec)\n",
    "    prec = precision_score(y_test, pred, average='macro')\n",
    "    print('Precision: ', prec)\n",
    "    \n",
    "    print('F1:', F1)\n",
    "    \n",
    "    return clf, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b42438",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd, v = classify(train = train, test = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4604695",
   "metadata": {},
   "source": [
    "# WriteprintsRFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1792df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writeprints = pd.read_csv('train_write.csv')\n",
    "test_writeprints = pd.read_csv('test_write.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ed187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_write(train, test, train_label, test_label):\n",
    "            \n",
    "        \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(data, label, stratify = label, test_size = 0.2, random_state = 1234)\n",
    "    \n",
    "    clf = RandomForestClassifier(random_state=1234,n_estimators=150,n_jobs=-1)\n",
    "    \n",
    "    train_corpus = train\n",
    "#     train_corpus = [\" \".join(x) for x in train_corpus]\n",
    "\n",
    "    test_corpus = test\n",
    "#     test_corpus = [\" \".join(x) for x in test_corpus]\n",
    "    \n",
    "    train_vector = train_corpus\n",
    "    test_vector = test_corpus\n",
    "    \n",
    "    y_train = train_label\n",
    "    y_test = test_label\n",
    "    \n",
    "    fit = clf.fit(train_vector,y_train)\n",
    "    pred = clf.predict(test_vector)\n",
    "    \n",
    "    print(classification_report(y_test, pred, labels = list(train_label.unique()),\n",
    "                                digits=4))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return y_test, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6945ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_write(train = train_writeprints.loc[:, train_writeprints.columns != 'label'],\n",
    "              test = test_writeprints.loc[:, test_writeprints.columns != 'label'],\n",
    "              train_label = list(train_writeprints['label']),\n",
    "              test_label = list(test_writeprints['label']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
